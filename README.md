Задание выполнил Черников Алексей, студент ВМК.
Основная линия жизни представлена в отчёте, здесь я кратко хочу сориентировать, что и где искать.

В custom_dataset.py лежит реализация кастомного датасета для более удобной работы с картинками, которые скачаны на жёсткий диск.

В config.json лежат пути к папкам с изображениями и немного параметров

В vit_model.py лежит код, использовавшийся при дообучении модели, взятой от hugging face

В utils.py лежат вспомогательные функции, в частности attack_pgd_and_save_images, с помощью которой я сохранил на диск атакованные изображения, 
чтобы на глаз посмотреть различия с оригинальными и быстрее в следующий раз работать с ними, а не каждый раз по новой атаковать.

В test.py лежат функции для тестирования модели на изображениях. При этом есть функция для проведения атаки во время тестирования (on-the-fly так скатзать)

В vit_model.py лежит моя не самая успешная попытка самому реализовать визуальный трансформер. Он работает, но обучить не получилось до нормальных показаний.
Буду оправдывать себя слабым железом и малым количеством изображений для обучения. Где-то читал, что визуальные трансформеры надо тренировать на гигантских массивах данных.
А вообще реализовывать это всё дело начал т.к. неверно понял пункт задания с обучением классификатора.

Всё, что связано с анализом интерпретируемости лежит в ноутбуке interpretability_analys.ipynb
