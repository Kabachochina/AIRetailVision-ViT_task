21.03.2025 (пятница):
Начало работы над проектом.
- загрузил датасет с kaggle
- разделил категории на
лицензируемые: baby_products, beauty_health, electronics, grocery, pet_supplies
и нелицензируемые: clothing_accessories_jewellery, hobby_arts_stationary, home_kitchen_tools, sports_outdoor
- создал кастомный датасет CustomDataset для работы с изображениями
метка 0 обозначает, что товар нелицензируем, 1 - лицензируем
- начал изучать, что такое vision transformer.
https://arxiv.org/pdf/2006.03677 - статья по vit

22.03.2025 (суббота):
Продолжаю разбираться с vision transformer
просмотрел некоторые материалы про attention, transformer
наткнулся на статью https://arxiv.org/pdf/2010.11929
(AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE)

23.03.2025 (воскресенье):
начал работу над созданием vit модели

25.03.2025 (вторник):
написал классификатор на основе ViT. Буду тестировать его

26.03.2025(среда):
написал методы для тренировки и тестирования модели
написал методы для сохранения модели на диск и загрузки сохранённой модели

27.03.2025(Четверг):
Попробовал обучить модель, но на тесте показывала accuracy > 100%.
Дебажу и пытаюсь найти ошибку в реализации
Исправил ошибку. Она была в подсчёте correct в test_model

30.03.2025(воскресенье):
Теперь вместо обучения своей модели с нуля, буду заниматься fine tuning-ом
Знакомство с библиотекой transformers от hugging face
изменил класс custom_dataset, убрав transform и добавив processor: ViTImageProcessor
для использования подходящих трансформаций изображений перед подачей в предобученную модель
Пробую произвести дообучение модели google/vit-base-patch16-224-in21k

31.03.2025(понедельник):
дообучил модель и получил точность (accuracy) 92.32% на тестовой выборке
модель сохранил в saved_model
saved_model запушить не получилось (много весит) :(

